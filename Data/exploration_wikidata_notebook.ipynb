{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from extraction_croissement import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADP_loading_time:  11.364861965179443\n",
      "DL_loading_time:  56.09061288833618\n",
      "ILE_loading time:  18.45206594467163\n",
      "loading_data_time:  86.28106641769409\n",
      "recoupement des auteurs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102985/102985 [00:01<00:00, 73699.99it/s]\n"
     ]
    }
   ],
   "source": [
    "start_loading_data_time = time.time()\n",
    "\n",
    "# Loading des données sauvegardées dans la mémoire ram\n",
    "g_book_ADP = rdflib.Graph()\n",
    "g_author_ADP = rdflib.Graph()\n",
    "ADP_book_graph = g_book_ADP.parse(\"../Graphes/grapheADPLivres.rdf\")\n",
    "ADP_author_graph = g_author_ADP.parse(\"../Graphes/grapheADPAuteurs.rdf\")\n",
    "ADP_books = get_ADP_books(g_book_ADP, g_author_ADP)\n",
    "ADP_loading_time = time.time()\n",
    "print(\"ADP_loading_time: \", ADP_loading_time - start_loading_data_time)\n",
    "\n",
    "g_item_DL = rdflib.Graph()\n",
    "book_graph_DL = g_item_DL.parse(\"../Graphes/grapheDepotLegal.rdf\")\n",
    "DL_books = get_depot_legal_book(g_item_DL)\n",
    "DL_loading_time = time.time()\n",
    "print(\"DL_loading_time: \", DL_loading_time - ADP_loading_time)\n",
    "\n",
    "g_item_ILE = rdflib.Graph()\n",
    "item_graph_ILE = g_item_ILE.parse(\"../Graphes/grapheILE.rdf\")\n",
    "ILE_books = get_ILE_book(g_item_ILE)\n",
    "ILE_loading_time = time.time()\n",
    "print(\"ILE_loading time: \", ILE_loading_time - DL_loading_time)\n",
    "\n",
    "books_Hurtubise_file = open(\"./Hurtubise/Exportation-Hurtubise.csv\", \"r\", encoding='ISO-8859-1')\n",
    "csv_reader = csv.DictReader(books_Hurtubise_file, delimiter=',', fieldnames=[\n",
    "    \"Editeur\", \"ISBN Papier\", \"ISBN PDF\", \"ISBN epub\", \"Titre\", \"Sous - titre\", \"Titre de la serie\",\n",
    "    \"Contributeurs\", \"Contributeur(premier)\", \"Langue\", \"Langue Origine\", \"Resume\", \"Nombre de pages\",\n",
    "    \"Date de parution\", \"Annee de parution\", \"Sujet  THEMA principal\", \"Sujet THEMA\",\n",
    "    \"Quantificateur Georaphique\", \"Quantificateur de langue\", \"Quantificateur Historique\", \"Niveau soclaire FR\",\n",
    "    \"Niveau scolaire QC\", \"Cycle scolaire FR\", \"Niveau de lecture\", \"Echele CECR\", \"Quantificateur d'interet\",\n",
    "    \"Quantificateur d'age\", \"Quantificateur de style\", \"Classification Editoriale\", \"Mots cles\"\n",
    "\n",
    "])\n",
    "Hurtubise_books = get_Hurtubise_books(csv_reader)\n",
    "books_Hurtubise_file.close()\n",
    "\n",
    "authors_ILE_file = open(\"./ILE/auteurs_ILE_comma_separated.csv\", 'r', encoding='ISO-8859-1')\n",
    "csv_reader = csv.DictReader(authors_ILE_file, delimiter=',', fieldnames=[\n",
    "    'uri', 'nom', 'bio', 'genres', 'site', 'pseudonyme'])\n",
    "authors_ILE = [x for x in csv_reader]\n",
    "authors_ILE_file.close()\n",
    "\n",
    "authors_wikidata_file = open(\"./Wikidata/ecrivains_wikidata_comma_separated.csv\", 'r', encoding='ISO-8859-1')\n",
    "csv_reader = csv.DictReader(authors_wikidata_file, delimiter=',', fieldnames=[\n",
    "    'nom', 'uri'])\n",
    "authors_wikidata = [x for x in csv_reader]\n",
    "authors_wikidata_file.close()\n",
    "\n",
    "authors_DBpedia_file = open(\"./DBpedia/ecrivains_dbpedia_fr.txt\", \"r\", encoding='ISO-8859-1')\n",
    "csv_reader = csv.DictReader(authors_DBpedia_file, delimiter=';', fieldnames=[\n",
    "    'uri', 'nom'])\n",
    "authors_DBpedia = [x for x in csv_reader]\n",
    "authors_DBpedia_file.close()\n",
    "\n",
    "babelioJsonBooks = open(\"./Babelio/babelio_livres.json\", \"r\")\n",
    "Babelio_books = get_Babelio_books(json.load(babelioJsonBooks))\n",
    "babelioJsonBooks.close()\n",
    "\n",
    "babelioJsonAuthor = open(\"./Babelio/babelio_auteurs.json\", \"r\")\n",
    "Babelio_authors = get_Babelio_books(json.load(babelioJsonAuthor))\n",
    "babelioJsonAuthor.close()\n",
    "\n",
    "loading_data_time = time.time()\n",
    "print(\"loading_data_time: \", loading_data_time - start_loading_data_time)\n",
    "\n",
    "all_books = ADP_books + ILE_books + Hurtubise_books + Babelio_books + DL_books\n",
    "random.shuffle(all_books)\n",
    "\n",
    "author_ls = {}\n",
    "print('recoupement des auteurs')\n",
    "for book in tqdm(all_books, total=len(all_books)):\n",
    "    if len(book['author_raw']) == 1 and isinstance(book['author_raw'][0], list):\n",
    "        book['author_raw'] = book['author_raw'][0]\n",
    "    for author in book['author_raw']:\n",
    "        if author.replace('\"', '') not in author_ls:\n",
    "            author_ls[author.replace('\"', '')] = [book]\n",
    "        else:\n",
    "            author_ls[author.replace('\"', '')].append(book)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full find:  Michel Tremblay  with  Michel Tremblay  in the db\n",
      "reverse find:  Michel Tremblay  with  Michel  Tremblay  in the db\n",
      "reverse find:  Michel Tremblay  with  Michelle Tremblay-Lacoursière  in the db\n",
      "reverse find:  Michel Tremblay  with  MICHEL G. TREMBLAY  in the db\n",
      "full find:  Michel Tremblay  with  Pierre-Michel Tremblay  in the db\n",
      "reverse find:  Michel Tremblay  with  Michelle  Tremblay Lacoursière  in the db\n",
      "full find:  Anne Hébert  with  Anne Hébert  in the db\n",
      "reverse find:  Anne Hébert  with  Anne  Hébert  in the db\n",
      "full find:  Gabrielle Roy  with  Gabrielle Roy  in the db\n",
      "reverse find:  Gabrielle Roy  with  Gabrielle  Roy  in the db\n",
      "full find:  Marie Cardinal  with  Marie Cardinal  in the db\n",
      "reverse find:  Marie Cardinal  with  Marie-Josée Cardinal  in the db\n",
      "reverse find:  Réjean Ducharme  with  Réjean  Ducharme  in the db\n",
      "full find:  Jacques Ferron  with  Jacques Ferron  in the db\n",
      "reverse find:  Jacques Ferron  with  Jacques  Ferron  in the db\n",
      "full find:  Victor-Lévy Beaulieu  with  Victor-Lévy Beaulieu  in the db\n",
      "reverse find:  Victor-Lévy Beaulieu  with  Victor-Lévy  Beaulieu  in the db\n",
      "reverse find:  Marcel Dubé  with  Marcel  Dubé  in the db\n",
      "full find:  Marcel Dubé  with  Marcel Dubé  in the db\n",
      "full find:  Yves Thériault  with  Yves Thériault  in the db\n",
      "reverse find:  Yves Thériault  with  Yves  Thériault  in the db\n",
      "full find:  Jacques Poulin  with  Jacques Poulin  in the db\n",
      "reverse find:  Jacques Poulin  with  Jacques  Poulin  in the db\n",
      "full find:  André Langevin  with  André Langevin  in the db\n"
     ]
    }
   ],
   "source": [
    "# test sur le croissement des auteurs\n",
    "famous = ['Michel Tremblay', 'Anne Hébert', 'Gabrielle Roy', 'Marie Cardinal', 'Réjean Ducharme',\n",
    "                'Jacques Ferron', 'Victor-Lévy Beaulieu', 'Marcel Dubé', 'Yves Thériault', 'Jacques Poulin',\n",
    "                'André Langevin']\n",
    "for famous_author in famous:\n",
    "    for author in author_ls:\n",
    "        famous_author_part_1, famous_author_part_2 = famous_author.split(\" \")\n",
    "        re_part_1 = re.search(r\"{0}\".format(famous_author_part_1), author, flags=re.IGNORECASE)\n",
    "        re_part_2 = re.search(r\"{0}\".format(famous_author_part_2), author, flags=re.IGNORECASE)\n",
    "        re_full = re.search(r\"{0}\".format(famous_author), author, flags=re.IGNORECASE)\n",
    "        if re_part_1:\n",
    "            re_part_1_result = re_part_1.group()\n",
    "        if re_part_2:\n",
    "            re_part_2_result = re_part_2.group()\n",
    "        if re_full:\n",
    "            re_full_result = re_full.group()\n",
    "        if re_full:\n",
    "            print(\"full find: \", famous_author, \" with \", author, \" in the db\")\n",
    "        elif re_part_1 and re_part_2:\n",
    "            print(\"reverse find: \", famous_author, \" with \", author, \" in the db\")\n",
    "        elif (re_part_1 or re_part_2):\n",
    "            pass\n",
    "            #print(\"partial find: \", famous_author, \" with \", author, \" in the db\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Numero de prop importante:\n",
    "- sex or gender (P21)\n",
    "- country of citizenship (P27)\n",
    "- name in native language (P1559)\n",
    "- birth name (P1477)\n",
    "-  given name  (P735)\n",
    "- family name (P734)\n",
    "- date of birth (P569)\n",
    "- place of birth (P19)\n",
    "- date of death  (P570)\n",
    "- place of death  (P20)\n",
    "- occupation (P106)\n",
    "    - author (Q482980)\n",
    "    - writer (Q36180)\n",
    "- notable work (P800)\n",
    "- genre (P136)\n",
    "- award received (P166)\n",
    "- nominated for (P1411)\n",
    "- country of citizenship (P27)\n",
    "\n",
    "premiere query: ecrivain canadiens parlant/ecrivant en francais => 1232 resultats\n",
    "SELECT ?item ?itemLabel\n",
    "WHERE\n",
    "{{\n",
    "\n",
    "    ?item wdt:P31 wd:Q5 .\n",
    "    ?item wdt:P106 wd:Q36180 .\n",
    "    ?item wdt:P27 wd:Q16 .\n",
    "    ?item wdt:P1412 wd:Q150\n",
    "\n",
    "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\".}\n",
    "}}\n",
    "\n",
    "deuxieme query: ecrivain canadiens parlant/ecrivant en francais qui ont un produit notable => 82 resultats\n",
    "SELECT ?item ?itemLabel ?bookLabel\n",
    "WHERE\n",
    "{\n",
    "\n",
    "  ?item wdt:P31 wd:Q5 .\n",
    "  ?item wdt:P106 wd:Q36180 .\n",
    "  ?item wdt:P27 wd:Q16 .\n",
    "  ?item wdt:P1412 wd:Q150 .\n",
    "  ?item wdt:P800 ?book\n",
    "\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\".}\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT DISTINCT ?s ?book ?bookLabel\n",
    "WHERE\n",
    "{{\n",
    "    ?s wdt:P31 wd:Q5 .\n",
    "    {{ ?s wdt:P106  wd:Q36180 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q49757 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q214917 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q381353 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q6625963 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q4853732 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q5434338 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q1626130 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q10297252 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q18844224 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q15980158 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q26203955 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q11774202 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q1930187 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q487596 }} UNION\n",
    "    {{ ?s wdt:P106  wd:Q201788 }} .\n",
    "\n",
    "    {{ ?s rdfs:label \"{0}\"@fr }} UNION {{ ?s rdfs:label \"{0}\"@en }} UNION {{ ?s skos:altLabel \"{0}\"@fr }} .\n",
    "    OPTIONAL {{ ?s wdt:P800 ?book . }}\n",
    "\n",
    "    SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"fr,en\".}}\n",
    "}}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:56<00:00,  5.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tset query\n",
      "Nombre d'auteurs trouvés:  9  soit  81.81818181818181 %\n"
     ]
    }
   ],
   "source": [
    "# test with famous authors\n",
    "res = {}\n",
    "print('tset query')\n",
    "count = 0\n",
    "for author in tqdm(famous, total=len(famous)):\n",
    "    time.sleep(5)\n",
    "    test = q.format(author)\n",
    "    rep_wikidata_ecrivain = requests.get('https://query.wikidata.org/sparql?format=json&query=' + q.format(author))\n",
    "    if rep_wikidata_ecrivain.status_code == 200:\n",
    "        if len(rep_wikidata_ecrivain.json()['results']['bindings']) > 0:\n",
    "            count += 1\n",
    "            res[author] = {'id':rep_wikidata_ecrivain.json()['results']['bindings'][0]['s']['value'], 'books':[]}\n",
    "            for resultat in rep_wikidata_ecrivain.json()['results']['bindings']:\n",
    "                if 'book' in resultat:\n",
    "                    res[author]['books'].append({'book_id': resultat['book']['value'], 'book_label': resultat['bookLabel']['value']})\n",
    "print(\"Nombre d'auteurs trouvés: \", count, \" soit \", count * 100/len(famous), \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21515/21515 [7:14:56<00:00,  1.21s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query\n",
      "trop rapide !!!\n",
      "trop rapide !!!\n",
      "trop rapide !!!\n",
      "trop rapide !!!\n",
      "trop rapide !!!\n",
      "trop rapide !!!\n",
      "trop rapide !!!\n",
      "trop rapide !!!\n",
      "trop rapide !!!\n",
      "Nombre d'auteurs trouvés:  2582  soit  12.000929584011155 %\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "print('query')\n",
    "count = 0\n",
    "# for author in tqdm(author_ls.keys(), total=len(author_ls)):\n",
    "for author in tqdm(list(author_ls)[:], total=len(list(author_ls)[:])):\n",
    "    time.sleep(1)\n",
    "    rep_wikidata_ecrivain = requests.get('https://query.wikidata.org/sparql?format=json&query=' + q.format(author))\n",
    "    if rep_wikidata_ecrivain.status_code == 429:\n",
    "        print(\"trop rapide !!!\")\n",
    "    if rep_wikidata_ecrivain.status_code == 200:\n",
    "        if len(rep_wikidata_ecrivain.json()['results']['bindings']) > 0:\n",
    "            count += 1\n",
    "            res[author] = {'id':rep_wikidata_ecrivain.json()['results']['bindings'][0]['s']['value'], 'books':[]}\n",
    "            for resultat in rep_wikidata_ecrivain.json()['results']['bindings']:\n",
    "                if 'book' in resultat:\n",
    "                    res[author]['books'].append({'book_id': resultat['book']['value'], 'book_label': resultat['bookLabel']['value']})\n",
    "print(\"Nombre d'auteurs trouvés: \", count, \" soit \", count * 100/len(author_ls), \"%\")\n",
    "\n",
    "with open('wikidata_author_books_list.json', 'w') as outfile:\n",
    "    json.dump(res, outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-90f08e47f2a3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# test sur les auteurs de wikidata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mauthor\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mres\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mfamous_author\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mfamous\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0mfamous_author_part_1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfamous_author_part_2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfamous_author\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\" \"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mre_part_1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mre\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msearch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mr\"{0}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfamous_author_part_1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mauthor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mre\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIGNORECASE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "# test sur les auteurs de wikidata\n",
    "for author in res:\n",
    "    for famous_author in famous:\n",
    "        famous_author_part_1, famous_author_part_2 = famous_author.split(\" \")\n",
    "        re_part_1 = re.search(r\"{0}\".format(famous_author_part_1), author, flags=re.IGNORECASE)\n",
    "        re_part_2 = re.search(r\"{0}\".format(famous_author_part_2), author, flags=re.IGNORECASE)\n",
    "        re_full = re.search(r\"{0}\".format(famous_author), author, flags=re.IGNORECASE)\n",
    "        if re_part_1:\n",
    "            re_part_1_result = re_part_1.group()\n",
    "        if re_part_2:\n",
    "            re_part_2_result = re_part_2.group()\n",
    "        if re_full:\n",
    "            re_full_result = re_full.group()\n",
    "        if re_full:\n",
    "            print(\"full find: \", famous_author, \" with \", author, \" in the db\")\n",
    "            print(\"infos recoltées: \", json.dumps(res[author]))\n",
    "        elif (re_part_1 and re_part_2):\n",
    "            print(\"reverse find: \", famous_author, \" with \", author, \" in the db\")\n",
    "            print(\"infos recoltées: \", json.dumps(res[author]))\n",
    "        elif (re_part_1 or re_part_2):\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}