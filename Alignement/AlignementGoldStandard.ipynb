{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib import RDF, RDFS, OWL, XSD\n",
    "import json\n",
    "\n",
    "SCHEMA = Namespace(\"https://schema.org/\")\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "DBO = Namespace(\"http://dbpedia.org/ontology/\")\n",
    "SOGIDES = Namespace(\"http://www.sogides.com/\")\n",
    "SOGIDES_PROP = Namespace(\"http://www.sogides.com/prop/\")\n",
    "BANQ = Namespace(\"http://banq.qc.ca/\")\n",
    "WDT = Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
    "WD = Namespace(\"http://www.wikidata.org/entity/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des graphes RDF\n",
    "\n",
    "Nos disposons de cinq graphes RDF distincts:\n",
    "\n",
    "* Celui extrait des donnnées fournies par Messagerie ADP (séparé en deux: un graphe pour les auteurs et un autre pour les livres)\n",
    "* Celui extrait à partir du site de l'Infocentre littéraire des écrivains, L’ÎLE (http://recif.litterature.org/)\n",
    "* Celui construit à partir du Dépôt légal de BAnQ (https://www.donneesquebec.ca/recherche/fr/dataset/publications-recues-en-depot-legal)\n",
    "* Celui extrait des données fournies par Hurtubise\n",
    "* Celui extrait des données récupérées par Grégoire sur Babelio(séparé en deux: un graphe pour les auteurs et un autre pour les livres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N3003e0940af846858125b078a78f324a (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grapheAuteursADP = Graph()\n",
    "grapheAuteursADP.parse('../Graphes/grapheADPAuteurs.rdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N192feb00c3dc42cd9a9b5d6809220e4e (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grapheLivresADP = Graph()\n",
    "grapheLivresADP.parse('../Graphes/grapheADPLivres.rdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N703561a83ff0452a9ebd22b4cd2aa43e (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grapheILE = Graph()\n",
    "grapheILE.parse('../Graphes/grapheILE.rdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nab8c2b524be742b690c3021c43c7121b (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grapheDepotLegal = Graph()\n",
    "grapheDepotLegal.parse('../Graphes/grapheDepotLegal.rdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nb27aa539b190454e8d4bb5dcb91872cc (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grapheHurtubise = Graph()\n",
    "grapheHurtubise.parse('../Graphes/grapheHurtubise.rdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nf1610493629845639ae422484efbd081 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grapheBabelio = Graph()\n",
    "grapheBabelio.parse('../Graphes/grapheBabelio.rdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyer_unicode(c):\n",
    "    liste_codes =  {\n",
    "        'Ã\\xa0': 'à',\n",
    "        'Ã€': 'À',\n",
    "        'Ã¢': 'â',\n",
    "        'Ã‚': 'Â',\n",
    "        'Ã©': 'é',\n",
    "        'Ã\\x89': 'É',\n",
    "        'Ã\\xa8': 'è',\n",
    "        'Ã\\xaa': 'ê',\n",
    "        'Ã\\x8a': 'Ê',        \n",
    "        'Ã«': 'ë',\n",
    "        'Ã®':'î',\n",
    "        'Ã\\x8e':'Î',        \n",
    "        'Ã¯': 'ï', \n",
    "        'Ã´': 'ô',\n",
    "        'Ã\\x94': 'Ô',\n",
    "        'Ã¹': 'ù', \n",
    "        'Ã»': 'û',\n",
    "        'Å\\x93': 'œ', \n",
    "        'Â«': '«',\n",
    "        'Â»': '»',\n",
    "        'Ã§': 'ç',\n",
    "        'Ã\\x87': 'Ç',\n",
    "        'Âº': 'º',\n",
    "        'â\\x80\\x99': '’',\n",
    "        'â\\x80\\xa6' : '…',\n",
    "    }\n",
    "    \n",
    "    for code in liste_codes:\n",
    "        c = c.replace(code,liste_codes[code])\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978289006591X\n",
      "987289006591X\n",
      "987289006591X\n",
      "978289006591X\n",
      "978292088736X\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# def format_isbn(s):\n",
    "#     \"\"\"\n",
    "#     nettoyage du isbn, x-xxxxx-xxx-x (info) --> xxxxxxxxxx\n",
    "#     :param string: chaine de caractère à normaliser\n",
    "#     :return: même chaine de caractère normalisée\n",
    "#     \"\"\"\n",
    "#     string = re.sub(r'[^0-9]', '', s)\n",
    "#     if len(string) == 10:\n",
    "#         string = '978' + string\n",
    "#     string = string[:-1] + 'X'\n",
    "#     return string\n",
    "\n",
    "# import re\n",
    "\n",
    "def format_isbn(s):\n",
    "    \"\"\"\n",
    "    nettoyage du isbn, x-xxxxx-xxx-x (info) --> xxxxxxxxxx\n",
    "    :param string: chaine de caractère à normaliser\n",
    "    :return: même chaine de caractère normalisée\n",
    "    \"\"\"\n",
    "    string = re.sub(r'\\D', '', s)\n",
    "    if len(string) == 9 or len(string) == 12:\n",
    "        string += 'X'\n",
    "    if len(string) == 10:\n",
    "        string = '978' + string\n",
    "    string = string[:-1] + 'X' \n",
    "    return string\n",
    "\n",
    "print(format_isbn('289006591X'))\n",
    "print(format_isbn('9872890065913'))\n",
    "print(format_isbn('987289006591X'))\n",
    "print(format_isbn('2890065912'))\n",
    "print(format_isbn('292088736X (br.)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction de livres de ADP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qres = grapheLivresADP.query(\n",
    "    \"\"\"PREFIX schema: <https://schema.org/>\n",
    "       SELECT DISTINCT ?livre ?titre ?isbn\n",
    "       WHERE {\n",
    "          ?livre a <http://www.sogides.com/classe/Livre> ;\n",
    "             schema:name ?titre ;\n",
    "             schema:isbn ?isbn .\n",
    "       }\"\"\")\n",
    "\n",
    "#adp auteur\n",
    "#  ?auteur a <http://www.sogides.com/classe/Auteur> ;\n",
    "#              schema:name  ?nom . \n",
    "\n",
    "livres_adp = {}\n",
    "for r in qres:\n",
    "    livres_adp[format_isbn(r['isbn'].toPython())] = {\n",
    "         \"isbn\": r['isbn'].toPython(), \n",
    "         \"titre\": nettoyer_unicode(r['titre'])\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15469\n"
     ]
    }
   ],
   "source": [
    "print(len(livres_adp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction de livres Dépôt Légal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qres = grapheDepotLegal.query(\n",
    "     \"\"\"PREFIX ns1: <https://schema.org/>\n",
    "        SELECT DISTINCT ?livre ?isbn ?titre\n",
    "        WHERE {\n",
    "            ?livre a <http://dbpedia.org/ontology/Book>;\n",
    "                ns1:name ?titre ;\n",
    "                ns1:isbn ?isbn .\n",
    "        }\"\"\")\n",
    "\n",
    "livres_depot = {}\n",
    "for r in qres:\n",
    "    livres_depot[format_isbn(r['isbn'].toPython())] = {\n",
    "         \"isbn\": r['isbn'].toPython(), \n",
    "         \"titre\": nettoyer_unicode(r['titre'])\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60248\n"
     ]
    }
   ],
   "source": [
    "print(len(livres_depot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction livres Dépôt ILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qres = grapheILE.query(\n",
    "     \"\"\"PREFIX schema: <https://schema.org/>\n",
    "        SELECT DISTINCT ?livre ?isbn ?titre\n",
    "        WHERE {\n",
    "            ?livre a <http://recif.litterature.org/ontologie/classe/oeuvre> ;\n",
    "                schema:name ?titre ;\n",
    "                schema:isbn ?isbn .\n",
    "        }\"\"\")\n",
    "\n",
    "\n",
    "#ile auteur\n",
    "#            ?auteur a <http://recif.litterature.org/ontologie/classe/ecrivain> ;\n",
    "#              schema:givenName ?prenom ;\n",
    "#              schema:familyName ?nom .\n",
    "\n",
    "livres_ile = {}\n",
    "\n",
    "for r in qres:\n",
    "    isbns = re.split(\"[|;,]\", r['isbn'])\n",
    "    for isbn in isbns:\n",
    "        livres_ile[format_isbn(isbn)] = {\n",
    "            \"isbn\": r['isbn'].toPython(), \n",
    "            \"titre\": nettoyer_unicode(r['titre'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21073\n",
      "{'isbn': '292088736X (br.)', 'titre': 'La nuit verte du parc Labyrinthe'}\n"
     ]
    }
   ],
   "source": [
    "print(len(livres_ile))\n",
    "print(livres_ile['978292088736X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction livres Hurtubise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qres = grapheHurtubise.query(\n",
    "     \"\"\"PREFIX ns1: <http://schema.org/>\n",
    "        PREFIX hurtubise: <https://distributionhmh.com/onto/>\n",
    "        SELECT DISTINCT ?livre ?titre ?titreAlt ?isbn ?isbnpdf ?isbnepub\n",
    "        WHERE {\n",
    "            ?livre a <http://schema.org/Book> ;\n",
    "                ns1:name ?titre ;\n",
    "                ns1:isbn ?isbn .\n",
    "            OPTIONAL {\n",
    "            ?livre ns1:alternativeHeadline ?titreAlt;\n",
    "            }\n",
    "            OPTIONAL {\n",
    "            ?livre hurtubise:isbnpdf ?isbnpdf } .\n",
    "            OPTIONAL {\n",
    "            ?livre hurtubise:isbnepub ?isbnepub }\n",
    "        }\"\"\")\n",
    "\n",
    "livres_hurtubise = {}\n",
    "for r in qres:\n",
    "    livres_hurtubise[format_isbn(r['isbn'].toPython())] = {\n",
    "         \"isbn\": r['isbn'].toPython(), \n",
    "         \"titre\": nettoyer_unicode(r['titre'] + ' ' + r['titreAlt'])\n",
    "     }\n",
    "    if r['isbnpdf']:\n",
    "        livres_hurtubise[format_isbn(r['isbnpdf'].toPython())] = {\n",
    "         \"isbn\": r['isbnpdf'].toPython(), \n",
    "         \"titre\": nettoyer_unicode(r['titre'] + ' ' + r['titreAlt'])\n",
    "     }\n",
    "    if r['isbnepub']:\n",
    "        livres_hurtubise[format_isbn(r['isbnepub'].toPython())] = {\n",
    "         \"isbn\": r['isbnepub'].toPython(), \n",
    "         \"titre\": nettoyer_unicode(r['titre'] + ' ' + r['titreAlt'])\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2497\n",
      "{'isbn': '9782896478217', 'titre': \"Marika et ses amis - Tome 3 L'énigme du sommet Noir\"}\n"
     ]
    }
   ],
   "source": [
    "print(len(livres_hurtubise))\n",
    "print(livres_hurtubise['978289647821X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction livres Babelio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1793\n"
     ]
    }
   ],
   "source": [
    "qres = grapheBabelio.query(\n",
    "     \"\"\"PREFIX ns1: <https://schema.org/>\n",
    "        SELECT DISTINCT ?livre ?titre ?isbn\n",
    "         WHERE {\n",
    "            ?livre a <https://schema.org/Book> ;\n",
    "                ns1:name ?titre ;\n",
    "                ns1:isbn ?isbn .\n",
    "        }\"\"\")\n",
    "\n",
    "livres_babelio = {}\n",
    "print(len(qres))\n",
    "for r in qres:\n",
    "    livres_babelio[format_isbn(r['isbn'].toPython())] = {\n",
    "         \"isbn\": r['isbn'].toPython(), \n",
    "         \"titre\": nettoyer_unicode(r['titre'])\n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidats à l'alignement (gold standard)\n",
    "Livres confirmés comme étant le même par leur isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize(string):\n",
    "    \"\"\"\n",
    "    normalise une chaine de caractère pour faciliter leurs comparaisons\n",
    "    :param string: chaine de caractère à normaliser\n",
    "    :return: même chaine de caractère normalisée\n",
    "    \"\"\"\n",
    "    try:\n",
    "        string = re.sub(r'^\\W+|\\W+$', '', string)\n",
    "        string = re.sub(r'\\W', ' ', string)\n",
    "        string = re.sub(r' +', ' ', string)\n",
    "        string = re.sub(r',', '', string)\n",
    "        return string\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16103\n"
     ]
    }
   ],
   "source": [
    "alignement = {}\n",
    "\n",
    "set_adp_dep = set(livres_adp) & set(livres_depot)\n",
    "set_adp_ile = set(livres_adp) & set(livres_ile)\n",
    "set_adp_hur = set(livres_adp) & set(livres_hurtubise)\n",
    "set_adp_bab = set(livres_adp) & set(livres_babelio)\n",
    "set_ile_dep = set(livres_ile) & set(livres_depot)\n",
    "set_ile_hur = set(livres_ile) & set(livres_hurtubise)\n",
    "set_ile_bab = set(livres_ile) & set(livres_babelio)\n",
    "set_dep_hur = set(livres_depot) & set(livres_hurtubise)\n",
    "set_dep_bab = set(livres_depot) & set(livres_babelio)\n",
    "set_hur_bab = set(livres_hurtubise) & set(livres_babelio)\n",
    "\n",
    "isbns = set(set_adp_dep ^ set_adp_ile ^ set_adp_hur ^ set_ile_dep ^ set_ile_hur ^ set_ile_bab ^ set_dep_hur ^ set_dep_bab ^ set_hur_bab)\n",
    "print(len(isbns))\n",
    "for isbn in isbns:\n",
    "    \n",
    "    value = (isbn, '', '', '', '', '')\n",
    "    value = list(value)\n",
    "    \n",
    "    if isbn in livres_adp:\n",
    "        value[1] = livres_adp[isbn]\n",
    "    \n",
    "    if isbn in livres_ile:\n",
    "        value[2] = livres_ile[isbn]\n",
    "\n",
    "    if isbn in livres_depot:\n",
    "        value[3] = livres_depot[isbn]\n",
    "\n",
    "    if isbn in livres_hurtubise:\n",
    "        value[4] = livres_hurtubise[isbn]\n",
    "\n",
    "    if isbn in livres_babelio:\n",
    "        value[5] = livres_babelio[isbn]\n",
    "\n",
    "    alignement[isbn] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16103\n",
      "['978289647821X', '', '', {'isbn': '9782896478217', 'titre': 'Marika et ses amis, tome 3'}, {'isbn': '9782896478217', 'titre': \"Marika et ses amis - Tome 3 L'énigme du sommet Noir\"}, '']\n"
     ]
    }
   ],
   "source": [
    "print(len(alignement))\n",
    "print(alignement['978289647821X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('alignement.csv', 'w') as f:\n",
    "    \n",
    "    for isbn, book in alignement.items():  \n",
    "#         isbn = book[0]\n",
    "        try:\n",
    "            adp = normalize(book[1][\"titre\"])\n",
    "        except:\n",
    "            adp = ''\n",
    "        try:\n",
    "            ile = normalize(book[2][\"titre\"])\n",
    "        except:\n",
    "            ile = ''\n",
    "        try:\n",
    "            depot = normalize(book[3][\"titre\"])\n",
    "        except:\n",
    "            depot = ''\n",
    "        try:\n",
    "            hurt = normalize(book[4][\"titre\"])\n",
    "        except:\n",
    "            hurt = ''\n",
    "        try:\n",
    "            babelio = normalize(book[5][\"titre\"])\n",
    "        except:\n",
    "            babelio = ''\n",
    "    \n",
    "        f.write(\"%s, %s, %s, %s, %s, %s\\n\" % (isbn, adp, ile, depot, hurt, babelio))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des paires positives\n",
    "\n",
    "Pour créer des paires positives il nous faut isoler deux à deux les titres de livres identifiés comme équivalents dans deux sources de données.  \n",
    "\n",
    "Ensuite, on doit retirer les titres qui sont exactement identiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8182\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import csv \n",
    "import numpy as np\n",
    "\n",
    "pairs = []\n",
    "with open('positive.csv', 'w', encoding=\"utf-8\") as f:\n",
    "    for isbn, book in alignement.items():  \n",
    "        titres = []\n",
    "        try:\n",
    "            titres.append(book[1][\"titre\"])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            titres.append(book[2][\"titre\"])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            titres.append(book[3][\"titre\"])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            titres.append(book[4][\"titre\"])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            titres.append(book[5][\"titre\"])\n",
    "        except:\n",
    "            pass    \n",
    "        unique_titres = set(titres)\n",
    "        if len(unique_titres) > 1 :\n",
    "            pairs.append(list(combinations(set(titres), 2)))\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(list(combinations(set(titres), 2)))\n",
    "print(len(pairs))\n",
    "np.save(\"paires_pos\", pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-30760f4e4692>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medit_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "dist = []\n",
    "for pair in pairs:\n",
    "    dist.append(nltk.edit_distance(pair[0], pair[1]))\n",
    "\n",
    "plt.hist(dist, bins=10)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
