{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import json\n",
    "import Levenshtein\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "from Identification_couples_livres.extract_books_from_DB import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des auteurs dans Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes potentiellement pertinentes dans Wikidata sont les suivantes:\n",
    "\n",
    "* wd:Q36180 Écrivain\n",
    "    * wd:Q49757\t    poète\n",
    "    * wd:Q214917\tdramaturge\n",
    "    * wd:Q381353\tfemme de lettres\n",
    "    * wd:Q6625963\tromancier\n",
    "    * wd:Q4853732\tauteur de littérature pour la jeunesse\n",
    "    * wd:Q5434338\técrivain de fantasy\n",
    "    * wd:Q1626130\thomme de lettres\n",
    "    * wd:Q10297252\tauteur de roman policier\n",
    "    * wd:Q18844224\técrivain de science-fiction\n",
    "    * wd:Q15980158\tessayiste\n",
    "    * wd:Q26203955\tauteur de contes\n",
    "    * wd:Q11774202  essayiste\n",
    "    * wd:Q1930187   jounraliste\n",
    "    * wd:Q487596    dramaturge\n",
    "    * wd:Q201788    historien\n",
    "\n",
    "\n",
    "Dans une expérience préliminaire nous avons tenté de retrouver les personnes qui sont des instances de ces classes, nées au Canada et dont la langue est le français.\n",
    "\n",
    "Si on prend la liste des écrivains qu'on a ainsi extraite, et qu'on analyse les écrivains  qui ne se retrouvent pas dans DBpdedia, on peut faire les constatations suivantes:\n",
    "\n",
    "* Près du quart sont effectivement des écrivains québécois (les autres sont en général des auteurs hors Québec, des universitaires, ou des gens qui ne sont tout simplement pas écrivains)\n",
    "* Parmi les écrivains québécois, leur absence de la liste peut être expliquée par les raisons suivantes:\n",
    "    * Erreur dans l'écriture du nom, faisant en sorte que le nom ne correspond pas à l'URI dans DBpedia (Marc-André au lieu de Marc André, par exemple)\n",
    "    * La personne est présente dans Wikipedia mais pas dans DBpedia\n",
    "    * Dans la plupart des cas, les catégories associées à la personne n'ont pas permis de l'identifier clairement comme écrivain\n",
    "* Parmi les écrivains québécois, vraiment très peu sont membres de l'UNEQ (ce qui signifie que cela ne nous aiderait pas à les détecter)\n",
    "\n",
    "\n",
    "Il serait risqué d'utiliser cette liste extraite de Wikidata, puisqu'on aura environ 4000 instances qui ne sont pas des écrivains québécois.\n",
    "\n",
    "On va donc plutôt faire le contraire: on va tenter de prendre les écrivains que nous avons extrait de DBpedia et les retrouver dans Wikidata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "f_dbpedia_fr = open('../Data/DBpedia/ecrivains_dbpedia_fr.txt')\n",
    "f_dbpedia_en = open('../Data/DBpedia/ecrivains_dbpedia_fr.txt')\n",
    "\n",
    "ecrivains = set()\n",
    "for l in f_dbpedia_fr.readlines():\n",
    "    (_,nom) = l.strip().split(' ; ')\n",
    "    ecrivains.add(nom)\n",
    "f_dbpedia_fr.close()\n",
    "\n",
    "for l in f_dbpedia_en.readlines():\n",
    "    (_,nom) = l.strip().split(' ; ')\n",
    "    ecrivains.add(nom)\n",
    "f_dbpedia_en.close()\n",
    "\n",
    "\n",
    "q_ecrivain = \"\"\"\n",
    "SELECT  DISTINCT ?s \n",
    "WHERE \n",
    "{{\n",
    "\n",
    "  {{ ?s rdfs:label \"{0}\"@fr }} UNION {{ ?s rdfs:label \"{0}\"@en }} UNION {{ ?s skos:altLabel \"{0}\"@fr }}\n",
    "  \n",
    "  {{ ?s wdt:P106  wd:Q36180 }} UNION    \n",
    "  {{ ?s wdt:P106  wd:Q49757 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q214917 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q381353 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q6625963 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q4853732 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q5434338 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q1626130 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q10297252 }} UNION \n",
    "  {{ ?s wdt:P106  wd:Q18844224 }} UNION \n",
    "  {{ ?s wdt:P106  wd:Q15980158 }} UNION \n",
    "  {{ ?s wdt:P106  wd:Q26203955 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q11774202 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q1930187 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q487596 }} UNION\n",
    "  {{ ?s wdt:P106  wd:Q201788 }}\n",
    "\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "ecrivains_wikidata = []\n",
    "\n",
    "for e in ecrivains:\n",
    "    sleep(1)\n",
    "    print(\"---\" + e + \"----\")\n",
    "    rep_wikidata_ecrivain = requests.get('https://query.wikidata.org/sparql?format=json&query=' + q_ecrivain.format(e))\n",
    "    if rep_wikidata_ecrivain.status_code == 200:\n",
    "        if len(rep_wikidata_ecrivain.json()['results']['bindings']) > 0:\n",
    "            for resultat in rep_wikidata_ecrivain.json()['results']['bindings']:\n",
    "                ecrivains_wikidata.append((e, resultat['s']['value']))\n",
    "                print(resultat['s'])\n",
    "        else:\n",
    "            print(\"PAS TROUVÉ DANS WIKIDATA\")\n",
    "    else:\n",
    "        print('ERREUR:',e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sur les\",len(ecrivains), 'trouvés dans DBpedia, on en retrouve',len(ecrivains_wikidata), \"dans Wikidata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../Data/Wikidata/ecrivains_wikidata2.txt','w')\n",
    "for (nom,uri) in ecrivains_wikidata:\n",
    "    f.write(\"{}<>{}\\n\".format(nom,uri))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Recherche des auteurs des bases de données dans wikidata\n",
    "\n",
    "### Numéros de propriété importantes:\n",
    "\n",
    "- sex or gender (P21)\n",
    "- country of citizenship (P27)\n",
    "- name in native language (P1559)\n",
    "- birth name (P1477)\n",
    "-  given name  (P735)\n",
    "- family name (P734)\n",
    "- date of birth (P569)\n",
    "- place of birth (P19)\n",
    "- date of death  (P570)\n",
    "- place of death  (P20)\n",
    "- occupation (P106)\n",
    "    - author (Q482980)\n",
    "    - writer (Q36180)\n",
    "- notable work (P800)\n",
    "- genre (P136)\n",
    "- award received (P166)\n",
    "- nominated for (P1411)\n",
    "- country of citizenship (P27)\n",
    "\n",
    "On recherche par nom, et par occupation (occupation fille de \"ecrivant\"), et on en récupère les labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT DISTINCT ?s ?book ?bookLabel\n",
    "WHERE\n",
    "{{\n",
    "    ?s wdt:P31 wd:Q5 .\n",
    "    ?s wdt:P106 ?occup .\n",
    "    ?occup wdt:P279 wd:Q36180 .\n",
    "\n",
    "    {{ ?s rdfs:label \"{0}\"@fr }} UNION {{ ?s rdfs:label \"{0}\"@en }} UNION {{ ?s skos:altLabel \"{0}\"@fr }} .\n",
    "    OPTIONAL {{ ?s wdt:P800 ?book . }}\n",
    "\n",
    "    SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"fr,en\".}}\n",
    "}}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On test avec les acteurs connus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:15<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tset query\n",
      "Nombre d'auteurs trouvés:  11  soit  100.0 %\n"
     ]
    }
   ],
   "source": [
    "famous = ['Michel Tremblay', 'Anne Hébert', 'Gabrielle Roy', 'Marie Cardinal', 'Réjean Ducharme',\n",
    "                'Jacques Ferron', 'Victor-Lévy Beaulieu', 'Marcel Dubé', 'Yves Thériault', 'Jacques Poulin',\n",
    "                'André Langevin']\n",
    "\n",
    "search_results = {}\n",
    "print('tset query')\n",
    "nb_author_found = 0\n",
    "for author in tqdm(famous, total=len(famous)):\n",
    "    time.sleep(1)\n",
    "    rep_wikidata_ecrivain = requests.get('https://query.wikidata.org/sparql?format=json&query=' + q.format(author))\n",
    "\n",
    "    if rep_wikidata_ecrivain.status_code == 429:\n",
    "        print(\"trop rapide !!!\")\n",
    "\n",
    "    if rep_wikidata_ecrivain.status_code == 200:\n",
    "        if len(rep_wikidata_ecrivain.json()['results']['bindings']) > 0:\n",
    "            nb_author_found += 1\n",
    "            search_results[author] = {'id':rep_wikidata_ecrivain.json()['results']['bindings'][0]['s']['value'], 'books':[]}\n",
    "            for result in rep_wikidata_ecrivain.json()['results']['bindings']:\n",
    "                try:\n",
    "                    search_results[author]['books'].append({'book_id': result['book']['value'], 'book_label': result['bookLabel']['value']})\n",
    "                except KeyError:\n",
    "                    pass\n",
    "print(\"Nombre d'auteurs trouvés: \", nb_author_found, \" soit \", nb_author_found * 100/len(famous), \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut essayer avec tous les auteurs de la base de donnée mais ca prendrais beaucoup de temps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/26126 [00:14<8:50:14,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-8f73d770da44>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mnb_author_found\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mauthor\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_author_ls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtotal\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_author_ls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m     \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m     \u001B[0mrep_wikidata_ecrivain\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrequests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'https://query.wikidata.org/sparql?format=json&query='\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauthor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.isfile('../Data/raw_authors_ls.json'):\n",
    "    with open('../Data/raw_authors_ls.json', 'r') as input_file:\n",
    "        raw_author_ls = json.load(input_file, cls=BookJSONDecoder)\n",
    "else:\n",
    "    all_books = generate_all_books()\n",
    "    author_ls, raw_author_ls = generate_all_authors(all_books)\n",
    "\n",
    "\n",
    "search_results = {}\n",
    "print('query')\n",
    "nb_author_found = 0\n",
    "for author in tqdm(raw_author_ls, total=len(raw_author_ls)):\n",
    "    time.sleep(1)\n",
    "    rep_wikidata_ecrivain = requests.get('https://query.wikidata.org/sparql?format=json&query=' + q.format(author))\n",
    "\n",
    "    if rep_wikidata_ecrivain.status_code == 429:\n",
    "        print(\"trop rapide !!!\")\n",
    "\n",
    "    if rep_wikidata_ecrivain.status_code == 200:\n",
    "        if len(rep_wikidata_ecrivain.json()['results']['bindings']) > 0:\n",
    "            nb_author_found += 1\n",
    "            search_results[author] = {'id':rep_wikidata_ecrivain.json()['results']['bindings'][0]['s']['value'], 'books':[]}\n",
    "            for result in rep_wikidata_ecrivain.json()['results']['bindings']:\n",
    "                try:\n",
    "                    search_results[author]['books'].append({'book_id': result['book']['value'], 'book_label': result['bookLabel']['value']})\n",
    "                except KeyError:\n",
    "                    pass\n",
    "print(\"Nombre d'auteurs trouvés: \", nb_author_found, \" soit \", nb_author_found * 100/len(raw_author_ls), \"%\")\n",
    "\n",
    "with open('../Data/Wikidata/wikidata_author_&_books_found_by_name_search.json', 'w') as outfile:\n",
    "    json.dump(search_results, outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recherche de tout les auteurs, puis comparaison avec notre bases de donnée manuellement\n",
    "\n",
    "### Recherche de tout les auteurs\n",
    "Première query: ecrivains canadiens parlant/ecrivant en francais => 1232 resultats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT ?item ?itemLabel\n",
    "WHERE\n",
    "{{\n",
    "\n",
    "    ?item wdt:P31 wd:Q5 .\n",
    "    ?item wdt:P106 wd:Q36180 .\n",
    "    ?item wdt:P27 wd:Q16 .\n",
    "    ?item wdt:P1412 wd:Q150\n",
    "\n",
    "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\".}\n",
    "}}\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Deuxième query: ecrivain canadiens parlant/ecrivant en francais qui ont un produit notable => 82 resultats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT ?item ?itemLabel ?bookLabel\n",
    "WHERE\n",
    "{\n",
    "\n",
    "  ?item wdt:P31 wd:Q5 .\n",
    "  ?item wdt:P106 wd:Q36180 .\n",
    "  ?item wdt:P27 wd:Q16 .\n",
    "  ?item wdt:P1412 wd:Q150 .\n",
    "  ?item wdt:P800 ?book\n",
    "\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\".}\n",
    "}\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dernière query: auteurs francophones, leures oeuvres et prix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_status:  200\n",
      "success ! Nombre d\\e lignes:  25726\n"
     ]
    }
   ],
   "source": [
    "all_authors_query = \"\"\"\n",
    "SELECT DISTINCT ?author ?authorLabel ?bookLabel ?awardLabel\n",
    "WHERE\n",
    "{\n",
    "    ?author wdt:P31 wd:Q5 .\n",
    "    ?author wdt:P27 ?country .\n",
    "    ?country wdt:P2936 wd:Q150 .\n",
    "    ?author wdt:P106 ?occup .\n",
    "    ?occup wdt:P279 wd:Q36180\n",
    "\n",
    "    OPTIONAL { ?author wdt:P800 ?book . }\n",
    "    OPTIONAL { ?author wdt:P166 ?award . }\n",
    "\n",
    "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr,en\".}\n",
    "\n",
    "}\"\"\"\n",
    "rep_wikidata_ecrivain = requests.get('https://query.wikidata.org/sparql?format=json&query=' + all_authors_query)\n",
    "print('code_status: ', rep_wikidata_ecrivain.status_code)\n",
    "if rep_wikidata_ecrivain.status_code == 200:\n",
    "    if len(rep_wikidata_ecrivain.json()['results']['bindings']) > 0:\n",
    "        print('success ! Nombre d\\e lignes: ', len(rep_wikidata_ecrivain.json()['results']['bindings']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# On sauvegarde le résultat de la recherche car elle peut échouer en fonction de la charge sur les serveurs de wikidata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "if rep_wikidata_ecrivain.status_code == 200:\n",
    "    if len(rep_wikidata_ecrivain.json()['results']['bindings']) > 0:\n",
    "        with open('../Data/Wikidata/request_allfrench_author_books_price_wikidata.json', 'w') as output_file:\n",
    "            json.dump(rep_wikidata_ecrivain.json()['results']['bindings'], output_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On formate les infromation sous forme de dictionnaire"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "with open('../Data/Wikidata/request_allfrench_author_books_price_wikidata.json') as input_file:\n",
    "    res = json.load(input_file)\n",
    "\n",
    "cleaned_data = {}\n",
    "\n",
    "for result in res:\n",
    "    try:\n",
    "        cleaned_data[result['author']['value']]['works'].add(result['bookLabel']['value'])\n",
    "        cleaned_data[result['author']['value']]['awards'].add(result['awardLabel']['value'])\n",
    "    except KeyError:\n",
    "        cleaned_data[result['author']['value']] = {\n",
    "            'author_uri': result['author']['value'],\n",
    "            'author_label': result['authorLabel']['value'],\n",
    "            'works': {[result['bookLabel']['value']]} if 'bookLable' in result else set(),\n",
    "            'awards': {result['awardLabel']['value']} if 'awardLabel' in result else set()\n",
    "        }\n",
    "\n",
    "with open('../Data/Wikidata/parsed_request_allfrench_author_books_price_wikidata.json', 'w') as output_file:\n",
    "    json.dump(cleaned_data, output_file, cls=BookJSONEncoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparaison avec nos bases de données"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18846/18846 [07:56<00:00, 39.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre d'autheurs en commun:  1301  soit  6.353159488231273 %\n",
      "nombre d'autheurs reconnus:  1378  soit  1.059185242121445  auteur dans nos bases de donnée par auteur reconnu dans wikidata\n",
      "Frequence de reconnaissance des 10 auteurs de wikidata les plus reconnus:  [('Michel Côté', 3), ('Denise Boucher', 3), ('Marie José Thériault', 3), ('Michel Tremblay', 3), ('Sylvie Bérard', 3), ('Jean-Claude Lauzon', 2), ('Gaëtan Brulotte', 2), ('Anne Hébert', 2), ('Michel Marc Bouchard', 2), ('Denis Thériault', 2)]\n",
      "Répartition des livres des auteurs reconnus dans les bases de données: \n",
      "1/8:  {\"ILE\": 13478, \"ADP\": 2681, \"Babelio\": 2172, \"Depot_legal\": 8765, \"Hurtubise\": 334}\n",
      "20 premiers couples à la limite d'être considérés comme égaux\n",
      "Autheur DB:  david descoteaux                         Autheur wikidata:  david decoteau\n",
      "Autheur DB:  pierre lambert                           Autheur wikidata:  pierre aubert\n",
      "Autheur DB:  pierre hebert                            Autheur wikidata:  pierre aubert\n",
      "Autheur DB:  etienne poirier                          Autheur wikidata:  etienne perier\n",
      "Autheur DB:  michael colgan                           Autheur wikidata:  michael hogan\n",
      "Autheur DB:  francois ricard                          Autheur wikidata:  francois girard\n",
      "Autheur DB:  francois simard                          Autheur wikidata:  francois girard\n",
      "Autheur DB:  francois picard                          Autheur wikidata:  francois girard\n",
      "Autheur DB:  fernand emond                            Autheur wikidata:  bernard emond\n",
      "Autheur DB:  michael ulmer                            Autheur wikidata:  michael rymer\n",
      "Autheur DB:  patrick bernard                          Autheur wikidata:  patrick bernauw\n",
      "Autheur DB:  alain boudreault                         Autheur wikidata:  alain boudreau\n",
      "Autheur DB:  andre duhaime                            Autheur wikidata:  andre ducharme\n",
      "Autheur DB:  denyse langlois                          Autheur wikidata:  denis langlois\n",
      "Autheur DB:  dee henderson                            Autheur wikidata:  dell henderson\n",
      "Autheur DB:  jacques salome                           Autheur wikidata:  jacques savoie\n",
      "Autheur DB:  jacques benoit                           Autheur wikidata:  jacques w benoit\n",
      "Autheur DB:  jonathan huard                           Autheur wikidata:  jonathan hardy\n",
      "Autheur DB:  claude bernier                           Autheur wikidata:  claude meunier\n",
      "Autheur DB:  claude messier                           Autheur wikidata:  claude meunier\n"
     ]
    }
   ],
   "source": [
    "with open('../Data/Wikidata/parsed_request_allfrench_author_books_price_wikidata.json', 'r') as author_file:\n",
    "    wikidata_authors = json.load(author_file)\n",
    "\n",
    "if os.path.isfile('../Data/authors_ls.json'):\n",
    "    with open('../Data/authors_ls.json', 'r') as input_file:\n",
    "        author_ls = json.load(input_file, cls=BookJSONDecoder)\n",
    "else:\n",
    "    all_books = generate_all_books()\n",
    "    author_ls, raw_author_ls = generate_all_authors(all_books)\n",
    "\n",
    "# Couple dont on estime que les deux auteurs sont les mêmes\n",
    "couple_writers = []\n",
    "# Couple dont on estime que les deux auteurs sont différents mais à la limite d'être les mêmes\n",
    "neg_couple_writers = []\n",
    "\n",
    "# Compte les livres des auteurs par base de donnée (permet de voir si une base de donnée n'a aucun match)\n",
    "data_base_stats = {}\n",
    "# Compte les auteurs de wikidata qui ont été trouvé dans nos bases de donnée\n",
    "found_at_least_once = 0\n",
    "# Compte le nombre de couples\n",
    "nb_couple = 0\n",
    "# Compte le nombre de fois qu'un auteur de wikidata a été trouvé dans nos bases de donnée\n",
    "author_found_freq = {}\n",
    "\n",
    "for wiki_author_id, wiki_author_info in tqdm(wikidata_authors.items()):\n",
    "    normalised_wikidata_title = normalize(wiki_author_info['author_label'])\n",
    "    # Compte le nombre de fois que l'auteur wikidata a été associé a un auteur de nos bases de donnée\n",
    "    wiki_author_found_count = 0\n",
    "    for DB_author, DB_author_books in author_ls.items():\n",
    "        dist_auteur = Levenshtein.distance(DB_author, normalised_wikidata_title)\n",
    "        if max(1, min(len(DB_author), len(normalised_wikidata_title)) / 6) > dist_auteur > max(1, min(len(DB_author), len(normalised_wikidata_title)) / 8):\n",
    "            neg_couple_writers.append({\n",
    "                        'author_DB': {'name': DB_author, 'books': DB_author_books},\n",
    "                        'author_wiki': {'name': normalised_wikidata_title,\n",
    "                                        'name_raw': wiki_author_info['author_label'],\n",
    "                                        'info': wiki_author_info}\n",
    "                        })\n",
    "        elif dist_auteur < max(1, min(len(DB_author), len(normalised_wikidata_title)) / 8):\n",
    "\n",
    "            new_couple = {\n",
    "                        'author_DB': {'name': DB_author, 'books': DB_author_books},\n",
    "                        'author_wiki': {'name': normalised_wikidata_title,\n",
    "                                        'name_raw': wiki_author_info['author_label'],\n",
    "                                        'info': wiki_author_info}\n",
    "                    }\n",
    "\n",
    "            nb_couple += 1\n",
    "            wiki_author_found_count += 1\n",
    "\n",
    "            couple_writers.append(new_couple)\n",
    "            for book in DB_author_books:\n",
    "                try:\n",
    "                    data_base_stats[book.data_base] += 1\n",
    "                except:\n",
    "                    data_base_stats[book.data_base] = 1\n",
    "\n",
    "    if wiki_author_found_count:\n",
    "        found_at_least_once += 1\n",
    "        author_found_freq[wiki_author_info['author_label']] = wiki_author_found_count\n",
    "\n",
    "print(\"nombre d'autheurs en commun: \", found_at_least_once, \" soit \", found_at_least_once * 100 / len(list(author_ls)), \"%\")\n",
    "print(\"nombre d'autheurs reconnus: \", nb_couple, \" soit \", nb_couple/found_at_least_once, ' auteur dans nos bases de donnée par auteur reconnu dans wikidata')\n",
    "print(\"Frequence de reconnaissance des 10 auteurs de wikidata les plus reconnus: \", sorted(author_found_freq.items(), key=lambda item: item[1], reverse=True)[:10])\n",
    "\n",
    "\n",
    "print(\"Répartition des livres des auteurs reconnus dans les bases de données: \")\n",
    "print('1/8: ', json.dumps(data_base_stats))\n",
    "\n",
    "print(\"20 premiers couples à la limite d'être considérés comme égaux\")\n",
    "for couple in neg_couple_writers[:20]:\n",
    "    print(\"Autheur DB: \", couple['author_DB']['name'] + \" \" * (40 - len(couple['author_DB']['name'])),\n",
    "          \"Autheur wikidata: \", couple['author_wiki']['name'])\n",
    "\n",
    "with open('../Data/Wikidata/couple_authors_wikidata.json', 'w') as outfile:\n",
    "    json.dump(couple_writers, outfile, cls=BookJSONEncoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On s'intéresse aux information récoltées sur ces auteurs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'artiste ayant des livres attribués:  50\n",
      "Nombre de livres global récupérés:  137\n",
      "Nombre d'artiste ayant des prix attribués:  422\n",
      "Nombre de prix global récupérés:  683\n",
      "exemple des prix:  ['prix littéraire PEN Oakland/Josephine Miles', \"grand officier de l'ordre national du Québec\", \"membre de l'Académie royale des arts du Canada\", 'Aurealis Award for best science fiction novel', \"grand officier de la Légion d'honneur\", 'Canadian Library Association Young Adult Book Award', 'prix Nils-Holgersson', 'prix du scénario du Festival de Cannes', \"Commonwealth Writers' Prize\", 'Prix Robert-Cliche', \"docteur honoris causa de l'université de Liège\", 'Prix Jeunesse des univers parallèles', \"Ours d'argent de la meilleure actrice\", 'prix Dan-David', 'Mårbacka Award', 'prix Femina', \"Grammy Award de l'album de l'année\", 'prix Goncourt de la poésie', 'Pour le Mérite pour les sciences et arts', 'Ethel Wilson Fiction Prize']\n"
     ]
    }
   ],
   "source": [
    "count_books = 0\n",
    "nb_books_for_each_wiki_author = []\n",
    "\n",
    "count_awards = 0\n",
    "nb_awards_for_each_wiki_author = []\n",
    "\n",
    "all_awards_name = set()\n",
    "\n",
    "for couple in couple_writers:\n",
    "    if couple['author_wiki']['info']['works']:\n",
    "        count_books += 1\n",
    "\n",
    "    if couple['author_wiki']['info']['awards']:\n",
    "        count_awards += 1\n",
    "        all_awards_name.update(couple['author_wiki']['info']['awards'])\n",
    "\n",
    "    nb_books_for_each_wiki_author.append(len(couple['author_wiki']['info']['works']))\n",
    "    nb_awards_for_each_wiki_author.append(len(couple['author_wiki']['info']['awards']))\n",
    "print(\"Nombre d'artiste ayant des livres attribués: \", count_books)\n",
    "print(\"Nombre de livres global récupérés: \", sum(nb_books_for_each_wiki_author))\n",
    "\n",
    "print(\"Nombre d'artiste ayant des prix attribués: \", count_awards)\n",
    "print(\"Nombre de prix global récupérés: \", sum(nb_awards_for_each_wiki_author))\n",
    "\n",
    "print(\"exemple des prix: \", list(all_awards_name)[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On veut confirmer nos couples d'auteur a partir des titres des livres qu'ils ont ecrits\n",
    "On va comparer les titres uns à uns.\n",
    "- Si un des titre ou plus correspond, alors on confirmera ce couple,\n",
    "- Si aucune titre n'est en commun, on considera le couple comme faux ou incomplet\n",
    "- Si on n'a pas récupéré de titre depuis wikidata alors on ne peut pas conclure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1378/1378 [00:00<00:00, 10303.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de couple:  1378\n",
      "nombre de couples confirmés par titres:  23\n",
      "nombre de couples infirmés par titres:  27\n",
      "nombre de couples sans titres de wikipedia:  1328\n"
     ]
    }
   ],
   "source": [
    "with open('../Data/Wikidata/couple_authors_wikidata.json', 'r') as input_file:\n",
    "    couple_writers = json.load(input_file, cls=BookJSONDecoder)\n",
    "\n",
    "# Listes pour stoker nos couples confirmé, invalidé et ceux dont on ne peut pas conclure car il n'y a pas de titres\n",
    "couples_confirmed = []\n",
    "couples_infirmed = []\n",
    "couples_unsure = []\n",
    "# Compte les cas ci-dessus\n",
    "count_checked_by_titles = 0\n",
    "count_no_titles = 0\n",
    "count_differentiate_by_titles = 0\n",
    "\n",
    "for couple in tqdm(couple_writers):\n",
    "    confirmed_by_title_match = False\n",
    "    confirmed_by_title_match_re = False\n",
    "\n",
    "    # On vérifie si on peut trouver des titres proches en comparant les titres parsés\n",
    "    # au titres normalisés de nos bases de donnée\n",
    "    book_titles_DB = [book.title for book in couple['author_DB']['books']]\n",
    "    for title in book_titles_DB:\n",
    "        normalised_wikidata_title_ls = [normalize(title_wikidata) for title_wikidata in couple['author_wiki']['info']['works']]\n",
    "        for title_wikidata in normalised_wikidata_title_ls:\n",
    "            dist_titles = Levenshtein.distance(title, title_wikidata)\n",
    "            if dist_titles < max(1, min(len(title), len(title_wikidata)) / 4):\n",
    "                confirmed_by_title_match = True\n",
    "                break\n",
    "    # On recherche par le suite le titre du livre directement dans les titres non nettoyé de la page wikipédia\n",
    "    # via expression régulières\n",
    "    for title in book_titles_DB:\n",
    "        for title_wiki_raw in couple['author_wiki']['info']['works']:\n",
    "            if re.search(normalize(title), normalize(title_wiki_raw)):\n",
    "                confirmed_by_title_match_re = True\n",
    "                break\n",
    "\n",
    "    # On liste les cas possibles: 0,1,2 tests réussis\n",
    "    if (not confirmed_by_title_match) and (not confirmed_by_title_match_re):\n",
    "        if couple['author_wiki']['info']['works']:\n",
    "            count_differentiate_by_titles += 1\n",
    "            couples_infirmed.append(couple)\n",
    "        else:\n",
    "            count_no_titles += 1\n",
    "            couples_unsure.append(couple)\n",
    "    else:\n",
    "        count_checked_by_titles += 1\n",
    "        couples_confirmed.append(couple)\n",
    "\n",
    "    # On sauvegarde comment avons nous trouvé les correspondances entre les deux listes de titres\n",
    "    couple['confirmed_by_title_match'] = confirmed_by_title_match\n",
    "    couple['confirmed_by_title_match_re'] = confirmed_by_title_match_re\n",
    "\n",
    "print('nombre de couple: ', len(couple_writers))\n",
    "print('nombre de couples confirmés par titres: ', count_checked_by_titles)\n",
    "print('nombre de couples infirmés par titres: ', count_differentiate_by_titles)\n",
    "print('nombre de couples sans titres de wikipedia: ', count_no_titles)\n",
    "\n",
    "with open('../Data/Wikidata/couple_authors_wikidata_confirmed.json', 'w') as outfile:\n",
    "    json.dump(couples_confirmed, outfile, cls=BookJSONEncoder)\n",
    "\n",
    "with open('../Data/Wikidata/couple_authors_wikidata_infirmed.json', 'w') as outfile:\n",
    "    json.dump(couples_infirmed, outfile, cls=BookJSONEncoder)\n",
    "\n",
    "with open('../Data/Wikidata/couple_authors_wikidata_unsure.json', 'w') as outfile:\n",
    "    json.dump(couples_unsure, outfile, cls=BookJSONEncoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extraction  des champs disponibles depuis DBpédia pour les auteurs en commun\n",
    "\n",
    "### Récupération de tout les champs\n",
    "\n",
    "Recherche de tout les champs disponibles depuis wikidata soit depuis tout les auteurs francophones,\n",
    "soit depuis les auteurs dont on a trouvé une instance dans notre base de donnée\n",
    "\n",
    "#### Recherche des URI de tout les auteurs de wikidata francophones"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18846/18846 [00:00<00:00, 653914.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_status:  200\n",
      "exemples: \n",
      "[\n",
      "  {\n",
      "    \"author\": {\n",
      "      \"type\": \"uri\",\n",
      "      \"value\": \"http://www.wikidata.org/entity/Q32335\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"author\": {\n",
      "      \"type\": \"uri\",\n",
      "      \"value\": \"http://www.wikidata.org/entity/Q33801\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "all_authors_query = \"\"\"\n",
    "SELECT DISTINCT ?author\n",
    "WHERE\n",
    "{\n",
    "    ?author wdt:P31 wd:Q5 .\n",
    "    ?author wdt:P27 ?country .\n",
    "    ?country wdt:P2936 wd:Q150 .\n",
    "    ?author wdt:P106 ?occup .\n",
    "    ?occup wdt:P279 wd:Q36180\n",
    "\n",
    "}\"\"\"\n",
    "rep_wikidata_ecrivain = requests.get('https://query.wikidata.org/sparql?format=json&query=' + all_authors_query)\n",
    "print('code_status: ', rep_wikidata_ecrivain.status_code)\n",
    "\n",
    "authors_uri = []\n",
    "if rep_wikidata_ecrivain.status_code == 200:\n",
    "    if len(rep_wikidata_ecrivain.json()['results']['bindings']) > 0:\n",
    "        print('exemples: ')\n",
    "        print(json.dumps(rep_wikidata_ecrivain.json()['results']['bindings'][:2], indent=2))\n",
    "        for result in tqdm(rep_wikidata_ecrivain.json()['results']['bindings']):\n",
    "            authors_uri.append(result['author']['value'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Seletion des champs:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1378/1378 [32:58<00:00,  1.44s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur code:  504\n"
     ]
    }
   ],
   "source": [
    "with open('../Data/Wikidata/couple_authors_wikidata.json', 'r') as input_file:\n",
    "    couple_writers = json.load(input_file, cls=BookJSONDecoder)\n",
    "\n",
    "result = {}\n",
    "# # Version pour tout les auteurs francophones\n",
    "# for uri in tqdm(authors_uri):\n",
    "# Version pour tout les auteurs dont on a trouvé un équivalent dans notre base de donnée\n",
    "for couple in tqdm(couple_writers):\n",
    "    uri = couple['author_wiki']['info']['author_uri'].split('/')[-1]\n",
    "    # partie générique\n",
    "    time.sleep(1)\n",
    "    get_all_fields_query = \"\"\"\n",
    "    SELECT ?pLabel ?objLabel\n",
    "    WHERE {{\n",
    "        wd:{0} ?predicate ?obj.\n",
    "        BIND( IRI(REPLACE( STR(?predicate),\"prop/direct/\",\"entity/\" )) AS ?p)\n",
    "        SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"fr, en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    rep_wikidata_ecrivain = requests.get('https://query.wikidata.org/sparql?format=json&query=' + get_all_fields_query.format(uri))\n",
    "\n",
    "    if rep_wikidata_ecrivain.status_code == 429:\n",
    "            print(\"trop rapide !!!\")\n",
    "\n",
    "    if rep_wikidata_ecrivain.status_code == 200:\n",
    "        if len(rep_wikidata_ecrivain.json()['results']['bindings']) > 0:\n",
    "\n",
    "            result[uri] = [(duo['pLabel']['value'], duo['objLabel']['value']) for duo in rep_wikidata_ecrivain.json()['results']['bindings']]\n",
    "    else:\n",
    "        print(\"erreur code: \", rep_wikidata_ecrivain.status_code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tri et sauvegarde des champs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Toutes les propriété possibles\n",
    "all_properties = set()\n",
    "for properties in result.values():\n",
    "    all_properties.update([property[0]for property in properties])\n",
    "\n",
    "# Pour chaque auteur, on compte combien de fois chaque propriété apparait\n",
    "properties_dict = {}\n",
    "for author_uri, properties in result.items():\n",
    "    for knowed_property in all_properties:\n",
    "        counter = 0\n",
    "        for property in properties:\n",
    "            if property[0] == knowed_property:\n",
    "                counter += 1\n",
    "        try:\n",
    "            properties_dict[knowed_property].append(counter)\n",
    "        except:\n",
    "            properties_dict[knowed_property] = [counter]\n",
    "\n",
    "# On tire des mesures du dictionnaire créé si desssus\n",
    "properties_resume = {}\n",
    "for knowed_property in properties_dict:\n",
    "    properties_resume[knowed_property] = {\n",
    "        # Moyenne du nombre de fois qu'apparait une propriété quand elle est présente chez un auteur\n",
    "        'non_null_mean': mean([e for e in properties_dict[knowed_property] if e]),\n",
    "        # Nombres d'auteur qui ont cette propriété\n",
    "        'nb_non_null': sum([1 for e in properties_dict[knowed_property] if e]),\n",
    "        # Nombre total de fois qu'apparait une propriété\n",
    "        'sum': sum(properties_dict[knowed_property]),\n",
    "    }\n",
    "\n",
    "# On sauvegarde ces mesures sous csv\n",
    "with open('../Data/Wikidata/list_properies_by_author.csv', 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=['name', 'non_null_mean', 'nb_non_null', 'sum' ])\n",
    "        writer.writeheader()\n",
    "        for rep_prop_name, rep_prop_dict in properties_resume.items():\n",
    "            if rep_prop_name.find(\"http://www.wikidata.org/prop/\") == -1:\n",
    "                rep_prop_dict['name'] = rep_prop_name\n",
    "                writer.writerow(rep_prop_dict)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}