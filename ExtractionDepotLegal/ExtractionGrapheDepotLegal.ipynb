{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "livres = []\n",
    "langues = {}\n",
    "auteurs = {}\n",
    "editeurs = {}\n",
    "titres = []\n",
    "categoriesujet = {}\n",
    "sujets = {}\n",
    "typepublication = {}\n",
    "typedocument = {}\n",
    "\n",
    "liste_codes = { \n",
    "                \"16.32\":\"Poésie\", \n",
    "                \"16.33\":\"Théatre\",\n",
    "                \"16.34\":\"Roman\",\n",
    "                \"16.35\":\"Contes/Nouvelles\",\n",
    "                \"16.38\":\"Jeunesse\",\n",
    "                \"16.41\":\"Bandes dessinées\"}\n",
    "    \n",
    "\n",
    "def extraireTitre(chaine):\n",
    "    return  chaine.split(' / ')[0].split(' : ')[0]\n",
    "                             \n",
    "\n",
    "class Livre:\n",
    "    def __init__(self, titre = \"***NO TITLE***\"):\n",
    "        self.id_depot_legal = \"\"\n",
    "        self.titre = titre\n",
    "        self.type = \"\"\n",
    "        self.langue = \"\"\n",
    "        self.langue_originale = \"\"\n",
    "        self.annee = \"\"\n",
    "        self.auteurs = []\n",
    "        self.isbn = []\n",
    "        self.editeur = None\n",
    "        \n",
    "    def show(self):\n",
    "        print('---', self.id_depot_legal, self.titre, '---')\n",
    "        print('   ',self.type, self.langue, end=\" \")\n",
    "        if self.langue_originale != self.langue:\n",
    "            print(\"({})\".format(self.langue_originale), end=\" \")\n",
    "        print(self.annee)\n",
    "        for a in self.auteurs:\n",
    "            print('   ', a.prenom, a.nom, end = ' : ')\n",
    "        print()\n",
    "        print(self.isbn)\n",
    "\n",
    "class Auteur():\n",
    "    def __init__(self,id,nom = \"\"):\n",
    "        self.id = id\n",
    "        nom_decompose = nom.split(',')\n",
    "        self.nom = nom_decompose[0].strip()\n",
    "        self.entites = {}\n",
    "        if len(nom_decompose) > 1:\n",
    "            self.prenom = nom_decompose[1].strip()\n",
    "        else:\n",
    "            self.prenom = \"\"\n",
    "            \n",
    "    def nom_complet(self):\n",
    "        return self.prenom + ' ' + self.nom\n",
    "  \n",
    "        \n",
    "class Editeur():\n",
    "    def __init__(self,nom = \"\"):\n",
    "        self.nom = nom\n",
    "        self.code = \"\"\n",
    "        self.categorie = \"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des données du dépot légal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auteur_id = 0\n",
    "\n",
    "with open('../Data/DepotLegal/depotlegal20171231.csv') as fichier_depot_legal:\n",
    "    depot_reader = csv.DictReader(fichier_depot_legal)\n",
    "    for data in depot_reader:\n",
    "        if data['SUJET'] in sujets:\n",
    "            sujets[data['SUJET']] += 1\n",
    "        else:\n",
    "            sujets[data['SUJET']] = 1\n",
    "\n",
    "        if data['TYPEPUBLICATION'] in typepublication:\n",
    "            typepublication[data['TYPEPUBLICATION']] += 1\n",
    "        else:\n",
    "            typepublication[data['TYPEPUBLICATION']] = 1\n",
    "            \n",
    "        if data['TYPE_DOCUMENT'] in typedocument:\n",
    "            typedocument[data['TYPE_DOCUMENT']] += 1\n",
    "        else:\n",
    "            typedocument[data['TYPE_DOCUMENT']] = 1\n",
    "  \n",
    "        if data['CATEGORIE_SUJET'] in categoriesujet:\n",
    "            categoriesujet[data['CATEGORIE_SUJET']] += 1\n",
    "        else:\n",
    "            categoriesujet[data['CATEGORIE_SUJET']] = 1\n",
    " \n",
    "        if data['LANGUE_PUBLICATION'] in langues:\n",
    "            langues[data['LANGUE_PUBLICATION']] += 1\n",
    "        else:\n",
    "            langues[data['LANGUE_PUBLICATION']] = 1            \n",
    "            \n",
    "        code_sujet = data['SUJET'][:5]\n",
    "        if code_sujet in liste_codes:\n",
    "            livre = Livre(extraireTitre(data[\"TITRE_PUBLICATION\"]))\n",
    "            titres.append(data[\"TITRE_PUBLICATION\"])\n",
    "            livre.type = liste_codes[code_sujet]\n",
    "            livre.annee = data['ANNEE_PUBLICATION']\n",
    "            livre.langue = data['LANGUE_PUBLICATION']\n",
    "            livre.id_depot_legal = data['ID_DEPOT']\n",
    "            if data['LISTE_ISBN_NETTOYE'] != '':\n",
    "                livre.isbn = data['LISTE_ISBN_NETTOYE'].split(';')\n",
    "            if data['LANGUE_ORIGINALE'] != \"\":\n",
    "                livre.langue_originale = data['LANGUE_ORIGINALE']\n",
    "            else:\n",
    "                livre.langue_originale = livre.langue\n",
    "            for a in data[\"LISTE_AUTEUR\"].split(';'):\n",
    "                if a not in auteurs:\n",
    "                    auteur_id += 1\n",
    "                    auteurs[a] = Auteur(auteur_id,a)\n",
    "                livre.auteurs.append(auteurs[a])\n",
    "            \n",
    "            editeur = Editeur(data['NOM_EDITEUR'])\n",
    "            editeur.code = data['CODE_EDITEUR']\n",
    "            editeur.categorie = data['CATEGORIE_EDITEUR']\n",
    "            \n",
    "            if data['CODE_EDITEUR'] not in editeurs:\n",
    "                editeurs[data['CODE_EDITEUR']] = editeur\n",
    "                \n",
    "            livre.editeur = editeur\n",
    "            \n",
    "            livres.append(livre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14420 auteurs\n",
      "56962 livres\n",
      "4505\n"
     ]
    }
   ],
   "source": [
    "print(len(auteurs), 'auteurs')\n",
    "print(len(livres), 'livres')\n",
    "print(len(editeurs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du graphe RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib import RDF, RDFS, OWL, XSD\n",
    "\n",
    "\n",
    "BANQ = Namespace(\"http://banq.qc.ca/\")\n",
    "SCHEMA = Namespace(\"https://schema.org/\")\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "DBO = Namespace(\"http://dbpedia.org/ontology/\")\n",
    "WDT = Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
    "WD = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56962 livres\n",
      "14420 auteurs\n",
      "4505 éditeurs\n",
      "533726 triplets dans le graphe\n"
     ]
    }
   ],
   "source": [
    "grapheDepotLegal = Graph()\n",
    "\n",
    "\n",
    "def creerUriAuteur(auteur):\n",
    "    return BANQ['auteur/' + str(auteur.id)]\n",
    "\n",
    "def creerUriEditeur(editeur):\n",
    "    return BANQ['editeur/' + str(editeur.code)]\n",
    "\n",
    "\n",
    "for a in auteurs.values():\n",
    "    grapheDepotLegal.add((creerUriAuteur(a), RDF.type, DBO['Writer']))\n",
    "    grapheDepotLegal.add((creerUriAuteur(a), SCHEMA.givenName, Literal(a.prenom)))\n",
    "    grapheDepotLegal.add((creerUriAuteur(a), SCHEMA.familyName, Literal(a.nom)))\n",
    "\n",
    "for e in editeurs:\n",
    "    grapheDepotLegal.add((creerUriEditeur(editeurs[e]), RDF.type, DBO['Publisher']))   \n",
    "    grapheDepotLegal.add((creerUriEditeur(editeurs[e]), SCHEMA.name, Literal(editeurs[e].nom)))\n",
    "    \n",
    "    \n",
    "for l in livres:\n",
    "    livre_uri = BANQ['livre/' + str(l.id_depot_legal)]\n",
    "    grapheDepotLegal.add((livre_uri,SCHEMA.name,Literal(l.titre)))\n",
    "    grapheDepotLegal.add((livre_uri,RDF.type,DBO['Book']))\n",
    "\n",
    "    for a in l.auteurs:\n",
    "        grapheDepotLegal.add((livre_uri,SCHEMA.author,creerUriAuteur(a)))\n",
    "    for i in l.isbn:\n",
    "        grapheDepotLegal.add((livre_uri,SCHEMA.isbn,Literal(i)))\n",
    "    \n",
    "    grapheDepotLegal.add((livre_uri,SCHEMA.inLanguage,Literal(l.langue)))\n",
    "    grapheDepotLegal.add((livre_uri,BANQ.type,Literal(l.type)))\n",
    "    grapheDepotLegal.add((livre_uri,SCHEMA.datePublished,Literal(l.annee)))\n",
    "\n",
    "    grapheDepotLegal.add((livre_uri,SCHEMA.publisher,creerUriEditeur(l.editeur)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533726 triplets dans le graphe\n"
     ]
    }
   ],
   "source": [
    "print(len(grapheDepotLegal),'triplets dans le graphe') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://schema.org/givenName Jean-Marie\n",
      "https://schema.org/familyName Gignac\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://dbpedia.org/ontology/Writer\n",
      "--- 24401 \"Le temps, l'espace et les autres demains\" ---\n",
      "    Poésie Français 1993\n",
      "    Renée Vaillancourt-Lauzière : \n",
      "['2893630057']\n"
     ]
    }
   ],
   "source": [
    "# pour tester\n",
    "\n",
    "for s,p,o in grapheDepotLegal.triples( (BANQ['auteur/' + '3473'], None, None) ):\n",
    "   print(p,o)\n",
    "\n",
    "livres[2378].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier_depot_legal = open(\"../Graphes/grapheDepotLegal.rdf\",\"wb\")\n",
    "grapheDepotLegal.serialize(fichier_depot_legal) \n",
    "fichier_depot_legal.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# À faire\n",
    "\n",
    "* Dans le cas de traductions (information indiquée dans le titre), il faudrait retrouver l'oeuvre originale\n",
    "* Il faut réfléchir à la catégorisation des livres (taxonomie)\n",
    "* Liens avec Wikidata, DBpedia et autres...\n",
    "* Plusieurs parutions des mêmes oeuvres\n",
    "* Traitement des titres nécessaire; ils contiennent souvent de l'information supplémentaire (format non standardisé):\n",
    "    * Livre en gros caractères\n",
    "    * Traducteur\n",
    "    * Auteur\n",
    "    * Illustrateur\n",
    "    * Catégorie\n",
    "    * Témoignages et notes\n",
    "    * Adaptation\n",
    "    * Autres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
